% NOTE -- ONLY EDIT THE .Rnw FILE!
% The .tex file will be overwritten.
%
%\VignetteIndexEntry{flowQB package}
%\VignetteDepends{flowCore}
%\VignetteKeywords{flowQB}
%\VignettePackage{flowQB}

\documentclass[11pt]{article}
\usepackage{times}
\usepackage{hyperref}
\usepackage[authoryear,round]{natbib}
\usepackage{times}
\usepackage{comment}
\usepackage{graphicx}
\usepackage{subfigure}

\textwidth=6.2in
\textheight=8.5in
\oddsidemargin=.1in
\evensidemargin=.1in
\headheight=-.3in

\newcommand{\scscst}{\scriptscriptstyle}
\newcommand{\scst}{\scriptstyle}
\newcommand{\Rfunction}[1]{{\texttt{#1}}}
\newcommand{\Rcode}[1]{{\texttt{#1}}}
\newcommand{\Robject}[1]{{\texttt{#1}}}
\newcommand{\Rpackage}[1]{{\textsf{#1}}}
\newcommand{\Rclass}[1]{{\textit{#1}}}

\usepackage{amsmath}
\usepackage{amscd}
\usepackage[tableposition=top]{caption}
\usepackage{ifthen}
\usepackage[utf8]{inputenc}
\usepackage{Sweave}

\begin{document}

\title{
    flowQB -- Automated Quadratic Characterization of Flow Cytometer Instrument
    Sensitivity\footnote{This project was supported by the Terry Fox
    Foundation, the Terry Fox Research Institute and the Canadian Cancer 
    Society. Josef Spidlen is an ISAC Marylou Ingram Scholar.}
}

\author{
    Josef Spidlen$^1$, Wayne Moore$^2$, Faysal El Khettabi, \\
    David Parks$^2$, Ryan Brinkman$^1$\\[12pt]
    $^1$\textit{Terry Fox Laboratory, British Columbia Cancer Agency}\\
    \textit{Vancouver, BC, Canada}\\[3pt]
    $^2$\textit{Genetics Department, Stanford University School of Medicine}\\
    \textit{Stanford, California, USA}
}

\maketitle

\section{Abstract}

This package provides methods to calculate flow cytometer's detection efficiency
(Q) and background illumination (B) by analyzing LED pulses and multi-level bead
sets. The method improves on previous formulations
\cite{wood1998, hoffman2007, chase1998} 
by fitting a full quadratic model with appropriate weighting, and by providing
standard errors and peak residuals as well as the fitted parameters themselves.
K-means clustering is incorporated for automated peak detection of multi-peak
data. Overall, this method is successful in providing good estimates of the
Spe scales and backgrounds for all of the fluorescence channels on instruments
with good linearity. 
Known photoelectron scales and measurement channel backgrounds make
it possible to estimate the precision of measurements at different signal levels
and the effects of compensated spectral overlap on measurement quality.

\section{Note - Vignette is a Work In Progress}
The code is already working and useable, but we don't have a proper
vignette yet, and the documentation is still a work-in-progress. We expect to
have this polished by the end of summer 2016.
In the mean time, please refer to the executable examples in the
reference manual or the unit tests included with this package.

\section{Introduction}

The basic measurement capabilities of a fluorescence cytometer measurement
channel can be estimated by knowing just two values:  Q, the statistical number
of photoelectrons (Spe) generated per unit of dye in the sample, and B, the
background light in dye equivalents that sets the minimum variance that
underlies all measurements.  From these the minimum detectable amount of dye
and the precision of measurements at different signal levels can be calculated.
Therefore, measurements of Q and B are the key to making valid comparisons
between different instruments and among different channels on an instrument.

We can achieve full specification of Q and B in two steps by evaluating
photoelectron scales for the measurement channels of interest and relating
those to measurements on dye reference samples.  There are problems and
challenges in implementing each step in a way that is convenient and accurate
in routine use. Here we address the photoelectron scale aspect by providing
reliable automated software for obtaining the needed information from LED or
multi-level, multi-dye bead data.

When a cell or particle moves through a sensing area on a flow cytometer, a 
focused laser beam excites fluorescent dyes that emit a pulse of light in all
directions. The optical system collects some of this light and passes it through
optical filters to the cathodes of one or more PMT detectors where a fraction of
the photons generate photoelectrons. The photoelectrons are amplified through a
series of dynodes to produce an output current pulse. The photoelectron
production is a Poisson process, so the variance of signals at a particular
level is proportional to the signal level itself. Since the amplification
process through the dynodes introduces some additional variance, we introduce
the term ``statistical photoelectrons'' or Spe to denote the effective Poisson
number relating signal levels and their variances.

Since it is difficult to measure photoelectron counts directly, the usual method
for estimating photoelectron scales has been to measure uniform light signals
at various levels and fit the measured means and variances to a statistical
model involving the Poisson distribution expectations for the relation between
them. Historically, two kinds of signal source have been used for this kind of
evaluation: an LED light source producing very uniform pulses at adjustable
signal levels or microspheres (also called “beads”) labeled with several
different concentrations of a mixture of fluorescent dyes.
The model can be expressed as a second-degree (quadratic) polynomial relating
the observed signal means and variances to Q, B and, for microsphere samples,
$CV_0$, a common non-statistical variability in the measurements of the
different microsphere peaks.

For measurements on a population of similar particles like one of the
populations in a multi-level bead set, the observed variance should be the sum
of the electronic noise, background light not associated with the particles,
Poisson variance related to the signal levels of the particles, the variation
in dye amount among the particles and illumination variations due to particles
taking different flow paths through the laser beam. The electronic noise and
background light combine into a variance contribution that is not dependent
on the signal level. The Poisson variance is proportional to the signal level,
and the dye and illumination variations combine to form $CV_0$ whose
contribution to the variances goes with the square of the signal level.
Therefore, the general equation for the observed variance and its components can
be expressed as 
$$V(M_I) = c_0 + c_1 M_I + c_2 M_I^2$$
where $M_I$ is the mean signal of the population in measurement intensity units,
and $V(M_I)$ is the observed variance of a population with mean $M_I$.
Methods implemented in this package fit sets of mean and variance data points
with this equation to obtain the parameters $c_0$, $c_1$ and $c_2$.
If we scale the signal levels in Spe, 
we can define $B_{\text{Spe}}$ as the effective background level in Spe and
$M_{\text{Spe}}$ as the mean signal in Spe.
Then, defining $Q_I$ as the Spe per intensity unit, as explained in our paper
\cite{parks2016}, we can calculate
$$B_{\text{Spe}} = c_0/c_1^2$$
$$Q_I = 1/c_1$$
$$CV_0^2 = c_2$$

\section{Requirements}

The flowQB package requires the \Rpackage{flowCore} library in order to
read FCS files \cite{spidlen2010},
the \Rpackage{stats} package for its model fitting and also
K-means clustering functinality, the
\Rpackage{extremevalues} package to determine outliers, and it also makes use
of some basic functions and classes from the \Rpackage{methods}
and \Rpackage{BiocGenerics} packages.
In addition, we suggest installing the
\Rpackage{flowQBData} package, which contains example data sets to demonstrate
the functionality of this package.
Alternativelly, one can use the \Rpackage{FlowRepositoryR} package in order
to work directly with data stored in FlowRepository.
In addition, we recommend the \Rpackage{xlsx} package in order to parse
house-keeping information from MS Excel spreadsheets.
Finally, we use the \Rpackage{RUnit} package in order to implement unit tests
assuring consistency and repreducibility of the \Rpackage{flowQB} functionality
over time.
Let's start by loading the \Rpackage{flowQB} package as well as the
\Rpackage{flowQBData} package with data to demonstrate the functionality
of this package.


<<LoadPackage, echo=true, results=hide>>=
library("flowQB")
library("flowQBData")
@

\section{Fitting LED pulser data}
An LED light pulser is producing very uniform pulses at adjustable signal
levels. White LEDs provide some signal at all visible wavelengths, but the 
far-red emission is weak. A given LED pulse level will generate quite
different photoelectron signals on different detectors, so it is important
to collect data over a wide range of LED levels to assure that the measurement
series on each detector will include the low, middle and high level signals
needed for optimal results in the fitting procedure. 
The \Rfunction{fit\_led} function assumes that data generated by different LED
levels are provided as separate FCS files.
These files are passed to the \Rfunction{fit\_led} function in the form 
of a vector of FCS file paths.
In addition, house keeping details about the data and the way the fitting
procedure should be performed need to be provided, resulting in the following
list of arguments:

\begin{itemize}

\item \Rcode{fcs\_file\_path\_list} -- A vector of FCS file paths pointing to 
data generated by an LED pulser set to a range of LED levels; different levels
generated different FCS files, all data comming from a single instrument.

\item \Rcode{ignore\_channels} -- A vector of short channel names (values of
the \$PnN keywords) specifying channels that should not be considered for
the fitting procedure. Normally, those should be all non-fluorescence channels,
such as the time and the (forward and side) scatter channels.

\item \Rcode{dyes} -- A vector of dye names that you would normally use with
the detectors specified below. This value does not affect the fitting, but
those dyes will be ``highlighted'' in the provided results.

\item \Rcode{detectors} -- A vector of short channel names (values of
the \$PnN keywords) specifying channels matching to the dyes specified above.
The length of this vector shall correspond to the length of the dyes vector.
These channels should be all of the same type as specified by the signal\_type
below, i.e., area, height or width of the measured signal.

\item \Rcode{signal\_type} -- The type of the signal specified as the ``area'',
``height'' or ``width''. This should match to the signal type that is being
captured by the channels specified in the detectors argument. The signal type is
being used in order to trigger type-specific peak validity checks. Currently,
if signal type equals to ``height'' then peaks with a mean value lower than
the lowest peak mean value are omitted from the fitting. In addition,
peaks that are not sufficiently narrow (\textit{i.e.}, exceeding a specific 
maximum CV) are also omitted from the fitting.
Currently, the maximum allowed CV is set to 0.65, but the code is designed 
to make this user-configureable and signal type dependent eventually.

\item \Rcode{instrument\_name} -- The make/model of the instrument. The 
purpose if this argument is to allow for instrument-specific peak validity
checks. At this point, if ``BD Accuri'' is passed as the instrument type, then
peaks with a mean value lower than the lowest peak mean value are omitted from
the fitting. Additional instrument-specific peak validity checks may be
implemented in the future.

\item \Rcode{bounds} -- On some instruments, the lowest LED peaks may be cut off
at a data baseline so that the peak statistics will not be valid.
Therefore, peaks too close to the baseline need to be excluded from the fitting.
Also, many instruments do not maintain good linearity to the full top of scale,
so it is also important to specify a maximum level for good linearity and, 
on each fluorescence channel, exclude any peak that is above that maximum.
The bounds argument shall provide a list specifying the minimum and maximum
value for the means of valid peaks; peaks with means outsize of this range will
be ignored for that particular channel.

\item \Rcode{minimum\_useful\_peaks} -- Different peaks may be omitted for
different channels due to various validity checks described above. 
This argument specifies the minimal number of valid peaks required in order
for the fitting procedure to be performed on a particular fluorescence channel.

\item \Rcode{max\_iterations} -- The peaks have a wide range of variances, so
unweighted least squares fitting is not appropriate, and we need to apply
appropriate weights in the fitting procedure. In particular, the populations
with lower variances get more weight since having the fit miss them by any
particular amount is worse than missing a high variance population by the
same amount. This argument specifies the maximum number of iterations for 
the iterative fitting approach with appropriate weight recalculations. 
In most cases, the fitting converges relativelly fast. 
The iterating stops when either the maximum of iterations is
used or if none of the coefficients of the model changed more than 0.00005.
The default maximum of 10 iterations seems to be enough in most cases. You
can also explore your results in order to see how many iterations were actually
done for each of the all of the fitting.

\end{itemize}

<<FitLED, echo=true, results=verbatim>>=
## Example is based on LED data from the flowQBData package
fcs_directory <- system.file("extdata", "SSFF_LSRII", "LED_Series", 
    package="flowQBData")
fcs_file_path_list <- list.files(fcs_directory, "*.fcs", full.names= TRUE)
## We are working with these FCS files:
basename(fcs_file_path_list)

## Various house keeping information
## - Which channels should be ignored, typically the non-fluorescence
##    channels, such as the time and the scatter channels
ignore_channels <- c("Time", 
    "FSC-A", "FSC-W", "FSC-H", 
    "SSC-A", "SSC-W", "SSC-H")
## - Which dyes would you typically use with the detectors
dyes <- c("APC", "APC-Cy7", "APC-H7", "FITC", "PE", "PE-Cy7", "PerCP", 
    "PerCP-Cy55", "V450", "V500-C")
## - What are the corresponding detectors, provide a vector of short channel 
## names, i.e., values of the $PnN FCS keywords.
detectors <- c("APC-A", "APC-Cy7-A", "APC-Cy7-A", "FITC-A", "PE-A", "PE-Cy7-A",
    "PerCP-Cy5-5-A", "PerCP-Cy5-5-A", "Pacific Blue-A", "Aqua Amine-A")
## - The signal type that you are looking at (Area, Height or Width)
signal_type <- "Area"
## - The instrument make/model
instrument_name <- 'LSRII'
## - Set the minimum and maximum values, peaks with mean outsize of this range
## will be ignored
bounds <- list(minimum = -100, maximum = 100000)
## - The minimum number of usable peaks (represented by different FCS files
## in case of an LED pulser) required in order for a fluorescence channel 
## to be included in the fitting. Peaks with mean expression outside of the 
## bounds specified above are omitted and therefore not considered useful
minimum_fcs_files <- 3 # The default 3 seems to be work well in typical cases
## - What is the maximum number of iterations for iterative fitting with
## weight adjustments
max_iterations <- 10 # The default 10 seems to be enough in typical cases

## Now, let's calculate the fitting
led_results <- fit_led(fcs_file_path_list, ignore_channels, dyes,
    detectors, signal_type, instrument_name, bounds = bounds,
    minimum_useful_peaks = minimum_fcs_files, max_iterations = max_iterations)
@

The results of the \Rfunction{fit\_led} function is a list with the following
components:

\begin{itemize}
\item \Rcode{peak\_stats} -- A list with summary stats for each of the
channels for all the different peaks (represented by different FCS files).
For each of the channels, peak stats are captured by a data frame with
rows corresponding to the different peaks (FCS files) and the following
columns:
\begin{itemize}
\item \Rcode{N}: the number of events in the peak
\item \Rcode{M}: the mean expression value for that peak
\item \Rcode{SD}: the standard deviation for that peak
\item \Rcode{V}: the variance for that peak (square of standard deviation)
\item \Rcode{W}: the weight of that peak
\item \Rcode{Omit}: was the peak omitted from the fitting? (TRUE or FALSE)
\item \Rcode{QR}: the residuals of the quadratic fitting
\item \Rcode{LR}: the residuals of the linear fitting
\item \Rcode{QR-I}: the residuals of the iterative quadratic fitting
\item \Rcode{LR-I}: the residuals of the iterative linear fitting
\end{itemize}
The values of \Rcode{W}, \Rcode{QR}, \Rcode{LR}, \Rcode{QR-I} and \Rcode{LR-I}
will ne \Rcode{NA} if \Rcode{Omit} is \Rcode{TRUE}.

<<ExploreLEDPeakStats, echo=true, results=verbatim>>=
## We have stats for these channels
names(led_results$peak_stats)

## Explore the peak stats for a randomly chosen channel (PE-Cy7-A)
## Showing only the head in order to limit the output for the vignette
head(led_results$peak_stats$`PE-Cy7-A`)
@

\item \Rcode{bg\_stats} -- A data frame with background stats for each channel.
These stats are a convenience way to look at peak stats of the lowest peak.
The columns of the data frame correspond to the different channels, and there
are the following rows:
\begin{itemize}
\item \Rcode{N}: the number of events in the lowest peak
\item \Rcode{M}: the mean expression value for the lowest peak
\item \Rcode{SD}: the standard deviation for the lowest peak
\end{itemize}

\item \Rcode{dye\_bg\_stats} -- A data frame with background stats for each 
``dye''. These are the same stats as \Rcode{bg\_stats} described above, but
the columns will only be restricted to the detectors/dyes that were listed
as arguments of the \Rfunction{fit\_led} call. The column headings are converted
from channel names (detectors) to ``dyes'' as per the mapping supplied by
the detectors and dyes arguments. The rows of the data frame are the same
as with the \Rcode{bg\_stats} described above.

<<ExploreBGStats, echo=true, results=verbatim>>=
## Explore bg_stats
led_results$bg_stats

## Explore dye_bg_stats
led_results$dye_bg_stats
@

\item \Rcode{fits} -- For the LED analysis, results are reported for both 
quadratic fitting and linear fitting (effectively fixing $CV_0 = 0$).
Since the uniformity of LED signal outputs is likely to be better than the 
ability of the cytometer electronics to evaluate them, the $c_2$ term in a 
quadratic fit should be very close to zero with a small standard error.
If the results of the quadratic fit are consistent with $CV_0 = 0$, 
we can rely on the linear fit results whose standard errors on $c_1$ will 
generally be smaller than the $c_1$ standard errors of the quadratic fit.

The \Rcode{fits} item contains a data frame with fits for each of the channels.
The columns of the data frame correspond to the different channels.
The rows of the data frame capture the coefficients of both, quadratic fitting
and linear fitting as follows:

\begin{itemize}
\item \Rcode{c0}: value of the $c_0$ coefficient of the quadratic fitting
\item \Rcode{c0 SE}: standard error of the $c_0$ coefficient of the quadratic
fitting
\item \Rcode{c0 P}: the P-value for the $c_0$ coefficient of the quadratic
fitting.
\item \Rcode{c1}: value of the $c_1$ coefficient of the quadratic fitting
\item \Rcode{c1 SE}: standard error of the $c_1$ coefficient of the quadratic
fitting
\item \Rcode{c1 P}: the P-value for the $c_1$ coefficient of the quadratic
fitting.
\item \Rcode{c2}: value of the $c_2$ coefficient of the quadratic fitting
\item \Rcode{c2 SE}: standard error of the $c_2$ coefficient of the quadratic
fitting
\item \Rcode{c2 P}: the P-value for the $c_2$ coefficient of the quadratic
fitting.
\item \Rcode{c0'}: value of the $c_0$ coefficient of the linear fitting
\item \Rcode{c0' SE}: standard error of the $c_0$ coefficient of the linear
fitting
\item \Rcode{c0' P}: the P-value for the $c_0$ coefficient of the linear
fitting.
\item \Rcode{c1'}: value of the $c_1$ coefficient of the linear fitting
\item \Rcode{c1' SE}: standard error of the $c_1$ coefficient of the linear
fitting
\item \Rcode{c1' P}: the P-value for the $c_1$ coefficient of the linear
fitting.
\end{itemize}

\item \Rcode{dye\_fits} -- A data frame with fits for each 
``dye''. These are the same stats as \Rcode{fits} described above, but
the columns will only be restricted to the detectors/dyes that were listed
as arguments of the \Rfunction{fit\_led} call. The column headings are converted
from channel names (detectors) to ``dyes'' as per the mapping supplied by
the detectors and dyes arguments. The rows of the data frame are the same
as with the \Rcode{fits} described above.

\item \Rcode{iterated\_fits} -- A data frame with fits for each of the channels
in the same way as for the \Rcode{fits} described above, but based on iterative
fitting with weights adjustments.

\item \Rcode{iterated\_dye\_fits} -- A data frame with fits for each of the 
``dyes'' in the same way as for the \Rcode{dye\_fits} described above, 
ut based on iterative fitting with weights adjustments.

<<ExploreFits, echo=true, results=verbatim>>=
## Explore dye_fits
## fits are the same rows but columns corresponding to all channels
led_results$dye_fits

## Explore iterated_dye_fits
## iterated_fits are the same rows but columns corresponding to all channels
led_results$iterated_dye_fits
@

\end{itemize}

\section{Fitting bead data}
TODO

\section{Parsing house-keeping information from spreadsheets}
TODO

%\section{Using data from FlowRepository}
%TODO

%\clearpage
\bibliographystyle{plainnat} 
\bibliography{Refs}

% 
% 
% \begin{itemize}
% \item {\bf Methods:} We propose a collection of R generic functions to 
% calculate Q, B and $CV_{intrinsic}$ quantities objectively and in a 
% time-efficient manner. We have implemented these functions in the 
% Bioconductor package flowQB. We illustrate their use in this draft.
% \item {\bf Results} We hope that these proposed R generic functions
% will become the base for the development of many tools to calculate
% Q, B and $CV_{intrinsic}$.
% \item {\bf keywords} Flow Cytometry, High Throughput, Doublet,
% Instrument Sensitivity, Kmeans, Mean Fluorescence Intensity (MFI),
% Molecules of Equivalent Soluble Fluorochrome (MESF),
% linear and quadratic regressions, Q (detector efficiency),
% B (background light level).
% \end{itemize}
% 
% \subsection*{\bf Illustration }
% 
% First read the data which is in a specific folder. Our data is in
% flowQB-extdata folder:
% 
% 
% 
% \subsection*{\bf RESULTS is a list }
% 
% The function BEADflowQBCalculation is used for the bead FCS file to
% determine the singlet events. These singlet events are clustered for the
% channels of interest to determine the raw statitics for the regression and
% the generation of the regression's coefficients, Q and B values.
% This function  generates the results as a list, the first element of the
% list is for Raw Statistics and the second element of the list is for the
% coefficients, Q and B values.
% 
% Raw Statistics uses 3 approaches, Robust Statistics, 
% Density estimation assuming a Gaussian distribution (MASS package)
% and the second 'extremevalues' package used to determine the raw
% statistics without outliers:
% 
% \begin{itemize}
% \item {\bf NE:} Number of events in each peak.
% \item {\bf mfiRS:} MFI associated to Robust Statistics.
% \item {\bf mfiGS:} MFI associated to Gauss estimation using MASS.
% \item {\bf mfino:} MFI associated to Gauss estimation using 'extremevalues'.
% \item {\bf mfirSD:} Standard deviation associated to Robust Statistics.
% \item {\bf mfiGS:} Std deviation associated to Gauss estimation using MASS.
% \item {\bf mfiSDno:} Standard deviation associated to Gauss estimation using
% 'extremevalues'.
% \item {\bf Nesno.ORD:} Number of events in each peak without outliers.
% \end{itemize}
% 
% For each approach (StatsProcedure) and channel (MARKER), the coefficients
% (c0,c1,c2) and (Q,B) are listed with their associated (Pvalue, Std-Error).

%\clearpage
%\bibliographystyle{abbrv}
%\begin{thebibliography}{}

%\bibitem{wood1998}
%J. Wood,
%{ \em Fundamental Flow Cytometer Properties Governing Sensitivity and
%Resolution}, 
%Cytometry 33, (1998), p.~ 260-6.
%
%\bibitem{hoffman2007}
%R. Hoffman and J. Wood,
%{\em  Characterization of Flow Cytometer Instrument Sensitivity},
%Current Protocols in Cytometry, Chapter 1: Unit 1.20 (2007).
%
%\bibitem{chase1998}
%E. Chase and R. Hoffman,
%{\em  Resolution of Dimly Fluorescent Particles: a Practical Measure of
%Fluorescence Sensitivity},
%Cytometry 33 (1998), p.~ 267-279.
%
%\bibitem{lt}
%D. R. Parks, m. Roederer, W. A. Moore,
%{\em A new "Logicle" display method avoids deceptive effects of logarithmic
%scaling for low signals and compensated data.}  Cytometry Part  (A), (2006),
%96(6), p.~541-51.
%
%\bibitem{OR}
%A. Ortyn, E. Hall, C. George, K. Frost, A. Basiji, J. Perry, A. Zimmerman,
%D. Coder, P. Morrissey,
%{\em  Sensitivity measurement and compensation in spectral imaging},
%Cytometry 69, (2006), p.~ 852 - 862.
%
%\bibitem{rs}
%{\em  Robust Statistics in BD FACSDivaTM 6.0 Software}, BD Tech Note
%$\# 23-9609-00$. (2007).
%
%
%\bibitem{r}
%R Development Core Team, 
%{\em R: A Language and Environment for Statistical Computing}, R Foundation for
%Statistical Computing, Vienna, Austria, (2011),
%
%\bibitem{BC}
%R. Ihaka  and R. Gentleman R. 
%{\em  A Language for Data Analysis and Graphics}, Journal of Computational and
%Graphical Statistics, vol. 5, No. 3, (1996), p.~299-314.
%
%
%\bibitem{mass}
%W. N. Venables and B. D. Ripley,
%{ \em Modern Applied Statistics with S}, Springer, Fourth Edition, New York,
%(2002).
%
%\bibitem{f}
%F. El Khettabi et al. 2014, 
%{\em Automated Quadratic Characterization of Flow Cytometer Instrument
%Sensitivit}, to be submitted. 
%\end{thebibliography}{}

\end{document}
